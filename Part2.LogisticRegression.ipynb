{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Part2.LogisticRegression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPUuA/vfdEfJBKm/paVARj1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#**(2)Logistic Regression(Supervised learning,Classification  Based)**\n","\n","- Logistic regression is a supervised learning **classification based** algorithm that is used to predict the **probability result of  the categorical dependent variable.**\n","- The dependent variable must be categorical in nature.It can be either Pass or Fail, 0 or 1.fraud-notfraud,“disease A vs disease B vs disease C”, \"low,Medium or High\"etc. but instead of giving the exact value as 0 and 1, it gives the probabilistic values which lie between 0 and 1.\n","\n","- Logistic Regression can be used for various classification problems such as Spam detection,Disease prediction,Result prediction etc\n"],"metadata":{"id":"qK7uSua2kxX2"}},{"cell_type":"markdown","source":["#**Type of Logistic Regression:**\n","\n","On the basis of the categories, Logistic Regression can be classified into three types:\n","\n","**(a)Binomial:**In binomial Logistic regression, there can be only two possible types of the dependent variables, such as 0 or 1, Pass or Fail,Phising or notphising,fraud-notFraud etc.\n","\n","**(b)Multinomial:**In multinomial Logistic regression, there can be 3 or more possible unordered types of the dependent variable, such “disease A” vs “disease B” vs “disease C”.\n","\n","**(c)Ordinal:**In ordinal Logistic regression, there can be 3 or more possible ordered types of dependent variables, such as \"low\", \"Medium\", or \"High\".\n"],"metadata":{"id":"YliDrUxQYxeb"}},{"cell_type":"markdown","source":["#**Sigmoid Function(Logistic Function):**\n","\n","- Since we have output  equation of linear regression as follows:\n","$$\\hat{y} = \\beta_0 + \\beta_1\\ x_1+....+\\beta_n\\ x_n$$\n","\n","- Mathmatically Sigmoid Function can be express as follows:\n","$$f(x) = \\frac 1 {1+ e^{-\\hat{y}}} $$\n","\n","- After putting the value of $\\hat{y}$ we get Sigmoid Function  as follows:\n","$$f(x) = \\frac 1 {1 + e^{-(\\beta_0 + \\beta_1\\ x_1+....+\\beta_n\\ x_n)}}$$ \n","\n","- If the value of $f(x)$ goes to $+ve$ infinity then the predicted value of $f(x)$ will become 1 and if it goes to $-ve$ infinity then the predicted value of $f(x)$ will become 0. And if the outcome of the sigmoid function is more than 0.5 then we classify that label as class 1 or positive class and if it is less than 0.5 then we can classify it to negative class or label as class 0.\n","\n","\n","\n","<figure align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1uAgt-s-w6sZdlfRXmo-cCQwY23eNJsDf\" height=\"200px\", width=\"300px\"> \n","</figure>\n","\n"],"metadata":{"id":"-l4wOXXKDtVP"}},{"cell_type":"markdown","source":["##**NOTE:**\n","\n","- Similarly we can also used **Loss function** of Logistic regression and taking partial derivatives of this loss function, after that apply **Gradient Descent techniques** to updates parameters for best fitting line in logistic regression.\n","\n","- Here,Formula of Loss Function in logistic regression is different than Formula of linear regression loss function but process is same."],"metadata":{"id":"uvRw9q00ujfh"}},{"cell_type":"markdown","source":["#**Evaluating the Performance of a Classification Model**\n","\n","##**Confusion Matrix:**\n","- The matrix is divided into two dimensions, that are predicted values and actual values.\n","<figure align=\"center\">\n","<img src=\"https://drive.google.com/uc?id=1EA0q7Kj0-9UQQj08k13F6RSkJWh3wrI4\" height=\"200px\", width=\"300px\"> \n","</figure>\n","\n","- The above matrix has the following cases:\n","\n","- **TP (True Positive):** Model has positive prediction $(\\hat{y} = 1)$ and actual value was also positive $(y = 1)$.\n","\n","- **TN (True Negative):**Model has negative prediction $(\\hat{y} = 0)$ and actual value was also negative $(y = 0)$.\n","\n","- **FP (False Positive)(Type I Error):** Model has positive prediction $(\\hat{y} = 1)$ but actual value was negative $(y = 0)$.\n","\n","- **FN (False Negative)(Type II Error):**Model has negative prediction $(\\hat{y} = 0)$ but actual value was positive $(y = 1)$.\n","\n","\n","\n","\n","\n","- We can used **from sklearn.metrics import plot_confusion_matrix** to compute the confusion matrix.\n","- With the help of confusion matrix we can evaluate the performance of a classification model as follows:\n","\n","##**(a)Accuracy:**\n","- It can be calculated as the ratio of the number of correct predictions made by the classifier to all number of predictions made by the classifiers. The formula is given below:\n","\n","$$\\text{Accuracy} = \\frac{\\text{Number of right predictions}}{\\text{Total number of predictions}}= \\frac{TP+TN}{TP+TN+FP+FN}$$\n","\n","- We can use **from sklearn.metrics import accuracy_score** to calculate accuracy score.\n","\n","- Accuracy may not be a good measure if the dataset is not balanced i.e Imbalance ratio between two or more classes.For Example 1000 message contain 990 not fraud and only 10 message are fraud.To solve this problem we apply the following methods.\n","\n","##**(b)Precision:**\n","- It can be calculated as the ratio of the number of True Positive made by the classifier to total number of positives prediction made by the classifiers. The formula is given below:\n","\n","$$\\text{Precision} = \\frac{\\text{True Positive}}{\\text{Total number of positives predicted}} = \\frac{TP}{TP+FP}$$\n"," \n","- We can use **from sklearn.metrics import precision_score** to calculate precision score.\n","\n","-  We apply Precision modul when the Type I Error(FP) is more dangerous.\n","\n","\n","##**(c)Recall:**\n","-  It is defined as the out of total positive classes, how our model predicted correctly. The recall must be as high as possible.\n","\n","$$\\text{Recall} =  \\frac{\\text{True Positive}}{\\text{Total number of actual positives}} = \\frac{TP}{TP + FN}$$\n","\n","- We can use **from sklearn.metrics import recall_score** to calculate recall score.\n","\n","- We apply Recall modul  when the Type II Error(FN) is more dangerous.\n","\n","##**(d)F1 Score:**\n","-  If two models have low precision and high recall or vice versa, it is difficult to compare these models. So, for this purpose, we can use F1-score. This score helps us to evaluate the recall and precision at the same time. The F-score is maximum if the recall is equal to the precision. It can be calculated using the below formula:\n","$$\\text{F1 score} = \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision}  + \\text{Recall}}$$ \n","\n","- We can use **from sklearn.metrics import f1_score** to calculate F1-score.\n","\n","- We apply F1 Score module when it is difficult to find whether Type I error is more dangerous or Type II error more dangerous."],"metadata":{"id":"KgYtqNFZLU4a"}},{"cell_type":"markdown","source":["##**Model building in Scikit-learn:**\n","- Let's build the diabetes prediction model.\n","- Here, we are going to predict diabetes using Logistic Regression Classifier.\n","- Let's first load the required Pima Indian Diabetes dataset using the pandas' read CSV function."],"metadata":{"id":"GNVmq2Uu0cHL"}},{"cell_type":"code","source":["from google.colab import drive     #mount your Google Drive in your virtual machine(VM).\n","drive.mount('/gdrive')              #Access  the data  drive because of different server of colab and drive."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vXDnWY2q1Ows","executionInfo":{"status":"ok","timestamp":1645870413872,"user_tz":-345,"elapsed":3892,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}},"outputId":"6342dc09-5410-43cc-f3b7-669594daacad"},"execution_count":311,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"],"metadata":{"id":"UUUKAeIx4cJk","executionInfo":{"status":"ok","timestamp":1645870417322,"user_tz":-345,"elapsed":510,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}}},"execution_count":312,"outputs":[]},{"cell_type":"code","source":["pima=pd.read_csv('/gdrive/My Drive/ML Project /Feature Engineering /4.ML Algorithms/diabetes.csv',quoting=3)\n","                                 #Read data file with path location step by step path location from My Drive."],"metadata":{"id":"LbEMoBJm1tAF","executionInfo":{"status":"ok","timestamp":1645870421109,"user_tz":-345,"elapsed":518,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}}},"execution_count":313,"outputs":[]},{"cell_type":"code","source":["pima.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"1nQQpuST4m0k","executionInfo":{"status":"ok","timestamp":1645870423997,"user_tz":-345,"elapsed":32,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}},"outputId":"31018a19-77a3-4ae3-a102-0d2ae91451f7"},"execution_count":314,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-9dbea912-d99e-4696-bbe1-adaaf9b49d24\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Pregnancies</th>\n","      <th>Glucose</th>\n","      <th>BloodPressure</th>\n","      <th>SkinThickness</th>\n","      <th>Insulin</th>\n","      <th>BMI</th>\n","      <th>DiabetesPedigreeFunction</th>\n","      <th>Age</th>\n","      <th>Outcome</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6</td>\n","      <td>148</td>\n","      <td>72</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>33.6</td>\n","      <td>0.627</td>\n","      <td>50</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>85</td>\n","      <td>66</td>\n","      <td>29</td>\n","      <td>0</td>\n","      <td>26.6</td>\n","      <td>0.351</td>\n","      <td>31</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>8</td>\n","      <td>183</td>\n","      <td>64</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>23.3</td>\n","      <td>0.672</td>\n","      <td>32</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>89</td>\n","      <td>66</td>\n","      <td>23</td>\n","      <td>94</td>\n","      <td>28.1</td>\n","      <td>0.167</td>\n","      <td>21</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>137</td>\n","      <td>40</td>\n","      <td>35</td>\n","      <td>168</td>\n","      <td>43.1</td>\n","      <td>2.288</td>\n","      <td>33</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dbea912-d99e-4696-bbe1-adaaf9b49d24')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9dbea912-d99e-4696-bbe1-adaaf9b49d24 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9dbea912-d99e-4696-bbe1-adaaf9b49d24');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   Pregnancies  Glucose  BloodPressure  ...  DiabetesPedigreeFunction  Age  Outcome\n","0            6      148             72  ...                     0.627   50        1\n","1            1       85             66  ...                     0.351   31        0\n","2            8      183             64  ...                     0.672   32        1\n","3            1       89             66  ...                     0.167   21        0\n","4            0      137             40  ...                     2.288   33        1\n","\n","[5 rows x 9 columns]"]},"metadata":{},"execution_count":314}]},{"cell_type":"markdown","source":["\n","Now,we need to divide the given columns into two types of variables dependent(or target variable) and independent variable(or feature variables)."],"metadata":{"id":"ZRJ-j7Ho5pMy"}},{"cell_type":"code","source":["#split dataset in features and target variable\n","feature_cols = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin', 'BMI','DiabetesPedigreeFunction','Age']\n","X = pima[feature_cols] # Features/independent variables\n","y = pima.Outcome # Target variable/dependent variables\n","\n","\n","# or Also we can write above code as this also. \n","X = pima.drop('Outcome', axis=1)   #Features/independent variables\n","y = pima['Outcome']               # Target variable/dependent variables"],"metadata":{"id":"kcKV8A-OQdKj","executionInfo":{"status":"ok","timestamp":1645870467394,"user_tz":-345,"elapsed":514,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}}},"execution_count":316,"outputs":[]},{"cell_type":"markdown","source":["Let's split dataset by using function train_test_split()."],"metadata":{"id":"VBvfucP08mvd"}},{"cell_type":"code","source":["# split X and y into training and testing sets\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"],"metadata":{"id":"YzUTDdxn8sQd","executionInfo":{"status":"ok","timestamp":1645870490841,"user_tz":-345,"elapsed":11,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}}},"execution_count":318,"outputs":[]},{"cell_type":"markdown","source":["Since, we have different range of features so we need to apply Feature Scaling techniques to bring features in same scale."],"metadata":{"id":"ED9GoY8jW792"}},{"cell_type":"code","source":["#Feature Scaling techniques to bring features in same scale.\n","from sklearn.preprocessing import RobustScaler # Or we can also use StandardScaler,MinMaxScaler depending on the dataset.\n","rb = RobustScaler()  \n","X_train = rb.fit_transform(X_train)\n","X_test = rb.transform(X_test)\n","\n","pd.DataFrame(X_train )   ##Convert numpy array generated by sklearn libraries to orginal dataframe.\n","pd.DataFrame(X_test )    ##Convert numpy array generated by sklearn libraries to orginal dataframe."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"tUBNcHL4G0M9","executionInfo":{"status":"ok","timestamp":1645870656134,"user_tz":-345,"elapsed":31,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}},"outputId":"84d04d54-0680-4224-fdf0-d4c82f338c56"},"execution_count":323,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-1eb5ea80-7775-4c00-a5de-a7986f85cd7b\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.6</td>\n","      <td>-0.487179</td>\n","      <td>-0.8750</td>\n","      <td>0.31250</td>\n","      <td>1.136802</td>\n","      <td>0.215633</td>\n","      <td>0.154466</td>\n","      <td>0.8750</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.2</td>\n","      <td>-0.128205</td>\n","      <td>0.1875</td>\n","      <td>0.28125</td>\n","      <td>-0.327553</td>\n","      <td>0.398922</td>\n","      <td>-0.603089</td>\n","      <td>-0.5000</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.2</td>\n","      <td>-0.230769</td>\n","      <td>-0.5000</td>\n","      <td>-0.71875</td>\n","      <td>-0.327553</td>\n","      <td>-0.129380</td>\n","      <td>-0.576226</td>\n","      <td>-0.5000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0</td>\n","      <td>-0.256410</td>\n","      <td>0.5000</td>\n","      <td>-0.71875</td>\n","      <td>-0.327553</td>\n","      <td>-0.797844</td>\n","      <td>1.298858</td>\n","      <td>0.3125</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.8</td>\n","      <td>0.487179</td>\n","      <td>1.1250</td>\n","      <td>-0.71875</td>\n","      <td>-0.327553</td>\n","      <td>-0.226415</td>\n","      <td>-0.436535</td>\n","      <td>1.3125</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>1.2</td>\n","      <td>1.230769</td>\n","      <td>1.0000</td>\n","      <td>-0.71875</td>\n","      <td>-0.327553</td>\n","      <td>-0.172507</td>\n","      <td>-0.189389</td>\n","      <td>1.2500</td>\n","    </tr>\n","    <tr>\n","      <th>150</th>\n","      <td>-0.4</td>\n","      <td>-1.025641</td>\n","      <td>-1.0000</td>\n","      <td>0.21875</td>\n","      <td>0.104046</td>\n","      <td>0.140162</td>\n","      <td>2.359973</td>\n","      <td>-0.3125</td>\n","    </tr>\n","    <tr>\n","      <th>151</th>\n","      <td>1.0</td>\n","      <td>-0.564103</td>\n","      <td>0.0000</td>\n","      <td>-0.71875</td>\n","      <td>-0.327553</td>\n","      <td>0.517520</td>\n","      <td>0.302216</td>\n","      <td>1.7500</td>\n","    </tr>\n","    <tr>\n","      <th>152</th>\n","      <td>-0.2</td>\n","      <td>0.743590</td>\n","      <td>-0.1250</td>\n","      <td>0.46875</td>\n","      <td>2.447013</td>\n","      <td>-0.431267</td>\n","      <td>-0.095366</td>\n","      <td>0.0000</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>1.0</td>\n","      <td>-1.102564</td>\n","      <td>-0.1250</td>\n","      <td>0.53125</td>\n","      <td>0.050096</td>\n","      <td>0.355795</td>\n","      <td>0.893217</td>\n","      <td>0.6250</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>154 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1eb5ea80-7775-4c00-a5de-a7986f85cd7b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1eb5ea80-7775-4c00-a5de-a7986f85cd7b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1eb5ea80-7775-4c00-a5de-a7986f85cd7b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["       0         1       2        3         4         5         6       7\n","0    0.6 -0.487179 -0.8750  0.31250  1.136802  0.215633  0.154466  0.8750\n","1   -0.2 -0.128205  0.1875  0.28125 -0.327553  0.398922 -0.603089 -0.5000\n","2   -0.2 -0.230769 -0.5000 -0.71875 -0.327553 -0.129380 -0.576226 -0.5000\n","3    1.0 -0.256410  0.5000 -0.71875 -0.327553 -0.797844  1.298858  0.3125\n","4    0.8  0.487179  1.1250 -0.71875 -0.327553 -0.226415 -0.436535  1.3125\n","..   ...       ...     ...      ...       ...       ...       ...     ...\n","149  1.2  1.230769  1.0000 -0.71875 -0.327553 -0.172507 -0.189389  1.2500\n","150 -0.4 -1.025641 -1.0000  0.21875  0.104046  0.140162  2.359973 -0.3125\n","151  1.0 -0.564103  0.0000 -0.71875 -0.327553  0.517520  0.302216  1.7500\n","152 -0.2  0.743590 -0.1250  0.46875  2.447013 -0.431267 -0.095366  0.0000\n","153  1.0 -1.102564 -0.1250  0.53125  0.050096  0.355795  0.893217  0.6250\n","\n","[154 rows x 8 columns]"]},"metadata":{},"execution_count":323}]},{"cell_type":"markdown","source":["Lets ,import the Logistic Regression module and create a Logistic Regression classifier object using LogisticRegression() function.\n","\n","Then, fit our model on the train set using fit() and perform prediction on the test set using predict()."],"metadata":{"id":"pRV5pWQI9cIA"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","logistic_regression = LogisticRegression()\n","logistic_regression.fit(X_train, y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vI88fZNo97_Q","executionInfo":{"status":"ok","timestamp":1645870677522,"user_tz":-345,"elapsed":533,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}},"outputId":"1843ac98-5880-418b-9b50-f84035ec8222"},"execution_count":324,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LogisticRegression()"]},"metadata":{},"execution_count":324}]},{"cell_type":"code","source":["y_pred = logistic_regression.predict(X_test)\n","pd.DataFrame(y_pred)         ##Convert numpy array generated by sklearn libraries to orginal dataframe.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"mBtdTi4J_ROw","executionInfo":{"status":"ok","timestamp":1645870722142,"user_tz":-345,"elapsed":490,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}},"outputId":"0db3c8e4-9bc0-4daf-d4f9-06194f1abb35"},"execution_count":327,"outputs":[{"output_type":"execute_result","data":{"text/html":["\n","  <div id=\"df-effd8b1b-347c-4819-b239-69a7647a2af4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>150</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>151</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>152</th>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>154 rows × 1 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-effd8b1b-347c-4819-b239-69a7647a2af4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-effd8b1b-347c-4819-b239-69a7647a2af4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-effd8b1b-347c-4819-b239-69a7647a2af4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["     0\n","0    0\n","1    0\n","2    0\n","3    0\n","4    0\n","..  ..\n","149  1\n","150  0\n","151  0\n","152  0\n","153  0\n","\n","[154 rows x 1 columns]"]},"metadata":{},"execution_count":327}]},{"cell_type":"markdown","source":["Model Evaluation using Confusion Matrix"],"metadata":{"id":"lZlKsPPX_Zs_"}},{"cell_type":"code","source":["from sklearn.metrics import plot_confusion_matrix\n","display = plot_confusion_matrix(logistic_regression,X_test,y_test)\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":334},"id":"krX1kc2wDsR0","executionInfo":{"status":"ok","timestamp":1645870802702,"user_tz":-345,"elapsed":1488,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}},"outputId":"dd93c181-d175-45cf-b169-87243b390473"},"execution_count":329,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n","  warnings.warn(msg, category=FutureWarning)\n"]},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAATIAAAEGCAYAAADmLRl+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAYQElEQVR4nO3debQV5Z3u8e9zDpMMMgiei4CCEc1Fo2gTx27bOETp9ka9S21N4uJ2a2NGTbyxo1lZsTur25juG6O3zSBqEtImDtEQMLFFRW2144QG04ISEaMMIrMyCZyzf/1H1YEDwtm7ZA9V5zyftWqdXbX3rvrB0Ye33nrrLUUEZmZF1tToAszM9pSDzMwKz0FmZoXnIDOzwnOQmVnh9Wh0AR0NHdIco0f1bHQZlsGrL/VvdAmWwabSerbEe9qTfZz+sX6xanVbRZ99/vebZ0bEGXtyvErkKshGj+rJszNHNboMy2Di2BMaXYJl8PTGX+/xPlatbuPZmftX9Nnm4a8O3eMDViBXQWZm+RdAiVKjy9iBg8zMMgmCrVHZqWW9OMjMLDO3yMys0IKgLWe3NjrIzCyzEg4yMyuwANocZGZWdG6RmVmhBbDVfWRmVmRB+NTSzAouoC1fOeYgM7NskpH9+eIgM7OMRBt7dN951TnIzCyTpLPfQWZmBZaMI3OQmVnBldwiM7Mic4vMzAovEG05myXfQWZmmfnU0swKLRBbornRZezAQWZmmSQDYn1qaWYF585+Myu0CNEWbpGZWcGV3CIzsyJLOvvzFR35qsbMcs+d/WbWJbR5HJmZFVkeR/bnqxozK4RSNFW0dEbSIZLmdFjelfQlSUMkPSTp1fTn4HL1OMjMLJPkpvGmipZO9xMxPyLGR8R44E+AjcA04CpgVkSMBWal653yqaWZZRKIrdW/RekU4LWIeEPSWcBJ6fapwGPAVzv7soPMzDKJIMuA2KGSZndYnxIRU3bxuQuAO9LXLRHxVvp6GdBS7iAOMjPLSFkGxK6MiAmd7k3qBXwCuHrn9yIiJJV9ZpODzMwyCTK1yCoxEXghIt5O19+WNDwi3pI0HFhebgfu7DezzKrR2d/BhWw/rQSYAUxKX08CppfbgVtkZpZJoKpNrCipH3AacGmHzdcBd0u6GHgDOL/cfhxkZpZJ8ji46kRHRGwA9tlp2yqSq5gVc5CZWUZ+QK+ZFVxA2VH79eYgM7PM3CIzs0KLkFtkZlZsSWe/n6JkZoXmOfvNrOCSzn73kZlZweVtYkUHmZllUs2R/dXiIDOzzPzwETMrtAjYWnKQmVmBJaeWDjIzKziP7O/CFi3ozbWfGb1tfdmbvbjoymUccfw6/vWqUWza0ETLyC189Xtv0G9AqXGF2jZD/8dmvvIvrzJ46FYi4N/vamH61P3oP3ArV9/4B1pGbObtJb351mWHsP5d/+8C+Rx+UdP2oaQzJM2XtEBS2SehFN2ogzbzg4fn84OH53PTzPn03qvECRPXcsNX9udvvraUmx+ZzwkT3+GeH+zb6FIt1dYmbvnWaC6deCRfPu9wzvzUMvY/aCPnX7qEOb8dyCWnHcWc3w7k/EsXN7rUHFFVHgdXTTU7kqRm4Hsk09iOAy6UNK5Wx8ubOU8MYPgBm2kZuZXFC3vzkWM3AHDkiet48jeDGlydtVuzohevzesPwKYNzSx6bS/2adnCcaes5uFpyT84D0/bl+NOXd3IMnOnlM7bX26pl1pG5tHAgohYGBFbgDuBs2p4vFx5bPogTjp7LQAHHPweTz0wEIAnfj2IFUt7NrI02419R7zHh8ZtYP6L/Rk0dCtrVvQCYM2KngwaurXB1eVHctWyuaKlXmoZZCOARR3WF6fbdiBpsqTZkmavWNVWw3LqZ+sW8fSDAznxfyVBdsX1b3Lf1H34/OkHs2l9Ez16lX0ojNVZn75tfP2m+dz8T2PYuH7nvjAR/pVt0z4gtpKlXhree5k+424KwIQj+nSJ/1yee2QAB31kI4OHtQKw/9jNfOvOhQAsfq03z8zau5Hl2U6ae5T4+k3zeXTGMH77YDLr8tqVPRk8bAtrVvRi8LAtvLPKreiO6nnaWIlatsiWAKM6rI9Mt3V5j/1q8LbTSoC1K5N/L0ol+PmNLZx50apGlWbvE3zp2tdY9NpeTPvxftu2Pv3IEE49J3kK2annLOepWUMaVWDutF+17C4tsueAsZLGkATYBcAna3i8XHhvYxMvPDGAy/95+1n1o78axH0/GQrACRPf4eMXuOM4Lw79k3Wces4KXn+lLzfNmAPA1O8cwN03j+BrN/6B089bzvIlvbn28oMbXGm+dJsBsRHRKukLwEygGfhRRMyt1fHyok/fEvfMfWmHbedcspJzLlnZoIqsM3Of35uJY4/f5XtXTzq0ztUUQ4Ro7S5BBhAR9wP31/IYZlZ/eRsQ2/DOfjMrljyO7HeQmVlmDjIzKzRPrGhmXUJ3GkdmZl1QBLSWmipaypE0SNI9kl6R9LKk4yQNkfSQpFfTn4PL7cdBZmaZVXFA7I3AAxHxYeAI4GXgKmBWRIwFZqXrnXKQmVkm1brXUtJA4ETgNoCI2BIRa0kml5iafmwqcHa5mhxkZpZZhCpagKHtk0Kky+QOuxkDrAB+LOl3km6V1A9oiYi30s8sA1rK1ePOfjPLLENn/8qImLCb93oARwFfjIhnJN3ITqeRERGSyk4m4RaZmWUSUbU+ssXA4oh4Jl2/hyTY3pY0HCD9ubzcjhxkZpaRaCs1VbR0JiKWAYskHZJuOgWYB8wAJqXbJgHTy1XkU0szyyyqNyD2i8DPJPUCFgJ/TdLAulvSxcAbwPnlduIgM7NMqnmvZUTMAXbVh3ZKlv04yMwsmyB3U387yMwss7zdouQgM7NMIu3szxMHmZll5lNLMyu8Kl61rAoHmZllEuEgM7MuwBMrmlnhuY/MzAotECVftTSzostZg8xBZmYZubPfzLqEnDXJHGRmlllhWmSS/pVOcjciLqtJRWaWawGUSgUJMmB23aows+IIoCgtsoiY2nFdUt+I2Fj7ksws7/I2jqzsYJD0gZnzgFfS9SMkfb/mlZlZfkWFS51UMqrtBuB0YBVARLxI8iw6M+uWKnsUXD0vCFR01TIiFkk7FNVWm3LMrBBydmpZSZAtknQ8EJJ6ApeTPNbczLqjgMjZVctKTi0/A3weGAEsBcan62bWbanCpT7KtsgiYiXwqTrUYmZFkbNTy0quWh4o6T5JKyQtlzRd0oH1KM7McqqAVy1/DtwNDAf2A34B3FHLoswsx9oHxFay1EklQdY3Iv4tIlrT5XagT60LM7P8iqhsqZfO7rUckr78d0lXAXeSZPFfAffXoTYzy6ucXbXsrLP/eZLgaq/40g7vBXB1rYoys3xTzjr7O7vXckw9CzGzgqhiR76kPwLrSAbZt0bEhPRs8C5gNPBH4PyIWNPZfioa2S/pMGAcHfrGIuKnH6RwMyu6qnfkfywd5tXuKmBWRFyXdmtdBXy1sx2UDTJJ1wAnkQTZ/cBE4EnAQWbWXdX21PIskswBmAo8Rpkgq+Sq5bnAKcCyiPhr4Ahg4Acu0cyKr1ThAkMlze6wTN5pTwE8KOn5Du+1RMRb6etlQEu5cio5tdwUESVJrZL2BpYDoyr4npl1RdkmVlwZERM6ef9PI2KJpH2BhyS9ssOhIkIqf2mhkiCbLWkQcAvJlcz1wFMVfM/MuqhqXbWMiCXpz+WSpgFHA29LGh4Rb0kaTtJ46lTZU8uI+FxErI2IHwKnAZPSU0wz666qcIuSpH6SBrS/Bj4OvATMACalH5sETC9XTmcDYo/q7L2IeKHczs3MOtECTEvnOuwB/DwiHpD0HHC3pIuBN4Dzy+2os1PL73TyXgAnV15vZf7w+76cvt/4au/WamjN/zm80SVYBq0zZlVlP9U4tYyIhSQXD3fevorkAmPFOhsQ+7HspZlZlxcU6hYlM7NdK8otSmZmu1OYey3NzHYrZ0FWyQyxkvRpSd9I1/eXdHTtSzOz3CrgDLHfB44DLkzX1wHfq1lFZpZrisqXeqnk1PKYiDhK0u8AImKNpF41rsvM8qyAVy23SmombShKGkb77aBm1i3lrbO/klPL/w9MA/aV9E8kU/hcW9OqzCzfctZHVslzLX8m6XmSkbYCzo4IP2ncrLuqc/9XJSqZWHF/YCNwX8dtEfFmLQszsxwrWpABv2H7Q0j6AGOA+cChNazLzHJMOeslr+TU8iMd19NZMT5Xs4rMzDLKPLI/Il6QdEwtijGzgijaqaWkKzqsNgFHAUtrVpGZ5VsRO/uBAR1et5L0md1bm3LMrBCKFGTpQNgBEfGVOtVjZkVQlCCT1CMiWiWdUM+CzCzfRLGuWj5L0h82R9IM4BfAhvY3I+KXNa7NzPKooH1kfYBVJHP0t48nC8BBZtZdFSjI9k2vWL7E9gBrl7M/hpnVVc4SoLMgawb6s2OAtcvZH8PM6qlIp5ZvRcQ361aJmRVHgYIsXzOnmVk+RLGuWmZ6QKaZdSNFaZFFxOp6FmJmxZG3PrJKZog1M9tRFWeIldQs6XeSfp2uj5H0jKQFku6q5BkhDjIzy6bSEKu81XY50HHW6W8D342Ig4A1wMXlduAgM7NMRPUeBydpJPCXwK3pukgG39+TfmQqcHa5/fhJ42aWWYY+sqGSZndYnxIRUzqs3wD8Hdtn2dkHWBsRren6YmBEuYM4yMwsu8qDbGVETNjVG5LOBJZHxPOSTtqTchxkZpZdda5angB8QtJfkNzTvTdwIzCoffYdYCSwpNyO3EdmZtlU2D9W7vQzIq6OiJERMRq4AHgkIj4FPAqcm35sEjC9XEkOMjPLrrYP6P0qcIWkBSR9ZreV+4JPLc0ss2rfohQRjwGPpa8XAkdn+b6DzMwyy9vIfgeZmWWzZ6eNNeEgM7PsHGRmVmTtI/vzxEFmZpmplK8kc5CZWTbuIzOzrsCnlmZWfA4yMys6t8jMrPgcZGZWaAV7ipKZ2ft4HJmZdQ2RryRzkJlZZm6RdXFXXP8mx5y6jrUre3DpyYcAcOChm7jsusX06lOirVXcdPVI5s/p2+BKDaBXj1Zu/tvp9OpRormpxKyXDuSWWR9lyuRf0bfXVgAG99/EvMX7cuXtZzS42pzoTgNiJf0IaJ+T+7BaHSdvHrxrCDN+PJQrb1y0bdslX1/K7de3MPvRvfnoye9y8deX8nfnHtTAKq3dltZmPnfbJ9i0pSfNTW3ccul0nvrD/kyesv3BPdd9ciaPvzy6cUXmUN46+2s5Q+xPgG73T9hLz/Rn3Zod/32IgH4D2gDot3cbq9/u2YjSbJfEpi3J76NHc4keTaUdun/69d7ChA8t4T/mjWlQffmkUmVLvdSsRRYRj0saXav9F8kPvzGCa+9YyN9+4y2k4MufGNvokqyDJpX46efvZeQ+73DP04cxd3HLtvf+fNzrPPfaSDZsLvuw6+4jyF1nf8Pn7Jc0WdJsSbO3srnR5dTEmZNWcfM1+/HpCeO4+e9HcMX1i8p/yeqmFE18+qbzOPPbFzFu1HIObFm97b2PH76AB190N8DOqvWA3mppeJBFxJSImBARE3rSu9Hl1MRp563myfsHAvD4fQM5ePzGBldku7L+vd48v3A/jhv7JgAD+27i0FHL+c/5+ze4shyq7cNHMmt4kHUHq97uyeHHbQBg/J+uZ+nrXTOwi2hQv03075OcCfTu0coxBy3mjRWDATjlsIU8+coBbGn1xf2O2gfE5qlF5t9QlV31/Tc4/Lj1DBzSyu2z5/Fv32nhhitH8tlvLqW5OdiyuYkbrhzZ6DItNXTARq459xGaFDQ1BQ//14d4cv4BAJx2+AKm/seRDa4whyK6z8SKku4ATgKGSloMXBMRZZ9PV3TXfe6AXW7/whkH17kSq8SCZftw0U3n7fK9z956Vp2rKZB85VhNr1peWKt9m1ljeWS/mRVbAN3l1NLMurB85ZiDzMyyy9uppYdfmFlmKkVFS6f7kPpIelbSi5LmSvqHdPsYSc9IWiDpLkllb6twkJlZNpUOhi3fatsMnBwRRwDjgTMkHQt8G/huRBwErAEuLrcjB5mZZZIMiI2Kls5EYn262jNdAjgZuCfdPhU4exdf34GDzMyyK1W4JONIZ3dYJnfcjaRmSXOA5cBDwGvA2ohoTT+yGBhRrhx39ptZZuVaWx2sjIgJu3szItqA8ZIGAdOAD3+QetwiM7NsqtdHtn2XEWuBR4HjgEGS2htZI4El5b7vIDOzjCq7YlnBVcthaUsMSXsBpwEvkwTauenHJgHTy1XkU0szy646EysOB6ZKaiZpVN0dEb+WNA+4U9I/Ar8Dyt6j7SAzs2yq9IDeiPg98L7pRSJiIXB0ln05yMwsu5xNde0gM7Ps8pVjDjIzy06lfD0PzkFmZtkE7YNdc8NBZmaZiPK3H9Wbg8zMsnOQmVnhOcjMrNDcR2ZmXYGvWppZwYVPLc2s4AIHmZl1Afk6s3SQmVl2HkdmZsXnIDOzQouAtnydWzrIzCw7t8jMrPAcZGZWaAGUmY+/3hxkZpZRQLiPzMyKLHBnv5l1Ae4jM7PCc5CZWbH5pnEzK7oAPI2PmRWeW2RmVmy+RcnMii4gcjaOrKnRBZhZAZWisqUTkkZJelTSPElzJV2ebh8i6SFJr6Y/B5crx0FmZtlFVLZ0rhX4vxExDjgW+LykccBVwKyIGAvMStc75SAzs2wikquWlSyd7ibeiogX0tfrgJeBEcBZwNT0Y1OBs8uV5D4yM8uu8quWQyXN7rA+JSKm7PwhSaOBI4FngJaIeCt9axnQUu4gDjIzyyiItrZKP7wyIiZ09gFJ/YF7gS9FxLuSth8pIiSVTU2fWppZNu3T+OxhZz+ApJ4kIfaziPhluvltScPT94cDy8vtx0FmZtlFqbKlE0qaXrcBL0fE9R3emgFMSl9PAqaXK8enlmaWSQBRnYkVTwAuAv5L0px029eA64C7JV0MvAGcX25HDjIzyyaqM7FiRDwJaDdvn5JlXw4yM8ssQ2d/XShydPOnpBUkTcmuZiiwstFFWCZd9Xd2QEQM25MdSHqA5O+nEisj4ow9OV4lchVkXZWk2eUuQVu++HdWLL5qaWaF5yAzs8JzkNXH+27JsNzz76xA3EdmZoXnFpmZFZ6DzMwKz0FWQ5LOkDRf0gJJZSeHs8aT9CNJyyW91OharHIOshqR1Ax8D5gIjAMuTGe/tHz7CVDzAZxWXQ6y2jkaWBARCyNiC3AnycyXlmMR8TiwutF1WDYOstoZASzqsL443WZmVeYgM7PCc5DVzhJgVIf1kek2M6syB1ntPAeMlTRGUi/gApKZL82syhxkNRIRrcAXgJkkj7m6OyLmNrYqK0fSHcBTwCGSFqezlFrO+RYlMys8t8jMrPAcZGZWeA4yMys8B5mZFZ6DzMwKz0FWIJLaJM2R9JKkX0jquwf7+omkc9PXt3Z2Q7ukkyQd/wGO8UdJ73vazu627/SZ9RmP9feSvpK1RusaHGTFsikixkfEYcAW4DMd35T0gZ5TGhGXRMS8Tj5yEpA5yMzqxUFWXE8AB6WtpSckzQDmSWqW9C+SnpP0e0mXAihxUzo/2sPAvu07kvSYpAnp6zMkvSDpRUmzJI0mCcwvp63BP5M0TNK96TGek3RC+t19JD0oaa6kW9n9U6S3kfQrSc+n35m803vfTbfPkjQs3fYhSQ+k33lC0oer8ZdpxeYnjRdQ2vKaCDyQbjoKOCwiXk/D4J2I+Kik3sB/SnoQOBI4hGRutBZgHvCjnfY7DLgFODHd15CIWC3ph8D6iPh/6ed+Dnw3Ip6UtD/J3Qv/E7gGeDIivinpL4FKRsX/TXqMvYDnJN0bEauAfsDsiPiypG+k+/4CyUNBPhMRr0o6Bvg+cPIH+Gu0LsRBVix7SZqTvn4CuI3klO/ZiHg93f5x4PD2/i9gIDAWOBG4IyLagKWSHtnF/o8FHm/fV0Tsbl6uU4Fx0rYG196S+qfH+N/pd38jaU0Ff6bLJJ2Tvh6V1roKKAF3pdtvB36ZHuN44Bcdjt27gmNYF+cgK5ZNETG+44b0f+gNHTcBX4yImTt97i+qWEcTcGxEvLeLWiom6SSSUDwuIjZKegzos5uPR3rctTv/HZi5j6zrmQl8VlJPAEkHS+oHPA78VdqHNhz42C6++zRwoqQx6XeHpNvXAQM6fO5B4IvtK5Lag+Vx4JPptonA4DK1DgTWpCH2YZIWYbsmoL1V+UmSU9Z3gdclnZceQ5KOKHMM6wYcZF3PrST9Xy+kD9C4maTlPQ14NX3vpyQzPOwgIlYAk0lO415k+6ndfcA57Z39wGXAhPRiwjy2Xz39B5IgnEtyivlmmVofAHpIehm4jiRI220Ajk7/DCcD30y3fwq4OK1vLp4+3PDsF2bWBbhFZmaF5yAzs8JzkJlZ4TnIzKzwHGRmVngOMjMrPAeZmRXefwPgg7s8bTNjzgAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["from sklearn import metrics\n","cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n","cnf_matrix"],"metadata":{"id":"m7u5XC4J_lyk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1645870808803,"user_tz":-345,"elapsed":488,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}},"outputId":"39f1476e-517d-4189-b2fa-09e118443c72"},"execution_count":330,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[79, 20],\n","       [18, 37]])"]},"metadata":{},"execution_count":330}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","accuracy = accuracy_score(y_test, y_pred)\n","print(accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wBo891FhDDVp","executionInfo":{"status":"ok","timestamp":1645870844946,"user_tz":-345,"elapsed":18,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}},"outputId":"58e1358c-93c2-4f5a-a683-197b1f5ece63"},"execution_count":332,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7532467532467533\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import precision_score\n","precision = precision_score(y_test, y_pred)\n","print(precision)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZGYYapyXDTZm","executionInfo":{"status":"ok","timestamp":1645870855083,"user_tz":-345,"elapsed":545,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}},"outputId":"6a669769-e43a-4be1-9967-48ecadec1728"},"execution_count":333,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6491228070175439\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import recall_score\n","recall = recall_score(y_test, y_pred)\n","print(recall)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8g_cpBn_Dgm6","executionInfo":{"status":"ok","timestamp":1645870858870,"user_tz":-345,"elapsed":554,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}},"outputId":"fd5c267a-b30a-4dbe-c3fa-608054e909ef"},"execution_count":334,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6727272727272727\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score \n","f1_score = f1_score(y_test, y_pred)\n","print(f1_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yDhSMKVcDk5V","executionInfo":{"status":"ok","timestamp":1645870863380,"user_tz":-345,"elapsed":543,"user":{"displayName":"Tapendra baduwal","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14382986397241314178"}},"outputId":"532f093b-af8a-4046-d442-29e095e7b954"},"execution_count":335,"outputs":[{"output_type":"stream","name":"stdout","text":["0.6607142857142858\n"]}]}]}